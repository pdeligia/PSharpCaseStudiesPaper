Distributed systems typically consist of two or more components that communicate \emph{asynchronously} by sending and receiving messages through a network layer~\cite{lamport1978time}. Each component has its own input message queue, and when a message arrives, the component responds by executing an appropriate \emph{message handler}. Such a handler consists of a sequence of program statements that might update the internal state of the component, send a message to another component in the system, or even create an entirely new component.

In a distributed system, message handlers can interleave in arbitrary order, because of the asynchronous nature of message-based communication. To complicate matters further, unexpected failures are the norm in production systems: nodes in a cluster might fail at any moment, and thus programmers have to implement sophisticated mechanisms that can deal with these failures and recover the state of the system. Moreover, with multicore machines having become a commodity, individual components of a distributed system are commonly implemented using multithreaded code, which adds another source of nondeterminism.

All the above sources of nondeterminism (as well as nondeterminism due to timeouts, message losses and client requests) can easily create \emph{Heisenbugs}~\cite{gray1986computers, musuvathi2008finding}, which are corner-case bugs that are difficult to detect, diagnose and fix. Techniques such as unit testing, integration testing and stress testing are heavily used in industry today for finding bugs in production code. However, these techniques are not effective for testing distributed systems, as they are not able to control the many sources of nondeterminism.

The goal of our work is to develop testing techniques to detect and debug Heisenbugs in distributed storage systems prior to deployment.
To achieve our goal, we use \psharp~\cite{deligiannis2015psharp}, a framework that provides: (i) an \emph{event-driven asynchronous programming} language for developing and modeling distributed systems; and (ii) a \emph{systematic concurrency testing} engine that can systematically explore all interleavings between asynchronous event handlers, as well as other nondeterministic events such as failures and timeouts.

A \psharp program consists of multiple \emph{state machines} that communicate with each other \emph{asynchronously} by sending and receiving \emph{events}, which may contain an optional \emph{payload}. A \psharp machine is similar to a class in \csharp: it can contain any number of fields and methods, but it also contains an input event queue, and one or more states. Each state can register \emph{actions} to handle incoming events. \psharp machines run concurrently with each other, each executing an event handling loop that dequeues an event from the input queue and handles it by invoking the registered action. This action might access a field, call a method, transition the machine to a new state, create a new machine, or send an event to another machine. In \psharp, a send operation is non-blocking; the event is simply enqueued into the input queue of the target machine, and it is up to the operating system scheduler to decide when to dequeue an event and handle it. All this functionality is provided in a lightweight runtime library, build on top of Microsoft's Task Parallel Library~\cite{leijen2009tpl}.

Our approach of using \psharp to test distributed systems, implemented in the .NET framework, requires the developer to perform the following three key modeling tasks. These tasks are illustrated in Section~\ref{sec:method} using the Azure Storage vNext as a running example.
\begin{enumerate}
\item
The computation model underlying \psharp is communicating state machines. The environment of the system-under-test must be modeled using the \psharp APIs, while the real components of the system must be wrapped inside \psharp machines. We call this modeled environment the \psharp test harness.

\item
All the asynchrony due to message passing between system components must become explicit and be modeled using the \psharp event-sending APIs. Similarly, all other sources of nondeterminism (e.g. failures and timer expiration) must be modeled using appropriate \psharp APIs. This step allows the \psharp runtime to systematically explore all asynchronous event handler interleavings and all other sources of nondeterminism during testing.

\item
The criteria for correctness of an execution must be specified. Specifications in \psharp can encode either \emph{safety} or \emph{liveness}~\cite{lamport1977proving} properties. Safety specifications generalize the notion of source code assertions; a safety violation is a finite trace leading to an erroneous state. Liveness specifications generalize nontermination; a liveness violation is an infinite trace that exhibits lack of progress.
\end{enumerate}

\psharp uses modern languages features such as \emph{interfaces} and \emph{virtual method dispatch} to connect the real code with the modeled code. Programmers in industry are used to work with such features, and heavily use them in production for testing purposes. In our experience, this significantly lowers the bar for product teams inside Microsoft to embrace \psharp for testing.

In principle, our modeling methodology is \emph{not specific} to \psharp and the .NET framework, and can be used in combination with any other programming framework that has equivalent capabilities. We also argue that our approach is \emph{flexible} since it allows the user to model \emph{as much} or \emph{as little} of the environment as required to achieve the desired level of testing.

\subsection{Specifications}
\label{sec:bg:bugs}
In  this section, we describe how safety and liveness specifications are expressed in \psharp.

{\bf Safety}.
In addition to the usual assertions that can be used to write safety properties that are local to a machine, \psharp also provides a way to specify global assertions by using a \emph{safety monitor}~\cite{desai2015building}, which is a special \psharp machine that can receive, but not send, events. A safety monitor maintain local state that is modified in response to events received from regular (i.e. non-monitor) machines. This local state is used to maintain a history of the computation that is relevant to the property being specified. An erroneous global behavior is flagged via an assertion on the private state of the safety monitor.

To declare a monitor, the programmer inherits from the \psharp \texttt{Monitor} class. Monitors in \psharp are singleton instances and, thus, a regular machine does not need a reference to a monitor to send an event to it.
A regular machine can send an event to a monitor by calling \texttt{Monitor<M>(e, p)}, where the parameter \texttt{e} is the event being send together with an optional payload \texttt{p}.

{\bf Liveness}.
Liveness property specifications are more difficult to encode since they are intended to capture program progress
over infinite executions.
Violation of a liveness property can only be demonstrated by an infinite execution.
Usually, a liveness property is specified via a temporal logic formula~\cite{Pnueli1977,lamport1994temporal}.
We take a different approach and allow the programmer to write a \emph{liveness monitor}.
Similar to a safety monitor, a liveness monitor receives events but does not send them.
Unlike a safety monitor, a liveness monitor~\cite{desai2015building}
contains three types of states---\emph{ordinary}, \emph{hot}, and \emph{cold}.
A hot state denotes a point in the execution where progress is required but has not happened yet,
e.g., a node has failed but a new one has not come up yet.
A liveness monitor enters a hot state upon receiving notification of an event that requires the system
to make progress and leaves the hot state upon receiving another event notifying it of progress.
An infinite execution is erroneous if the liveness monitor is in a hot state infinitely often but in a cold state only finitely often.
Our liveness monitors can encode arbitrary temporal logic properties.

A thermometer analogy is useful for understanding a liveness monitor.
A hot state increases the temperature by a small value.
A cold state resets the temperature to zero.
A liveness error happens if the temperature becomes infinite.
%The distinction between ordinary and cold states is useful for modeling progress for each instance of an infinite stream of events,
%such as a periodic request or a periodic timer expiration.

\subsection{Systematic testing}
\label{sec:psharp:testing}

The \psharp runtime is a lightweight layer build on top of the Task Parallel Library (TPL) of .NET that implements the semantics of \psharp: creating state machines, executing them concurrently using the default task scheduler of TPL, and sending events and enqueueing them in the appropriate machines. A key capability of the \psharp runtime is that it can execute in bug-finding mode for systematically testing a \psharp program to find bugs, such as assertion violations and uncaught exceptions. We now give an overview of how this works; more details can be found in a previous paper~\cite{deligiannis2015psharp}.

When the \psharp runtime runs in bug-finding mode, an embedded \emph{systematic concurrency testing engine}
~\cite{godefroid1997verisoft, musuvathi2008finding, emmi2011delay} captures and takes control of all sources
of non-determinism that are \emph{known} to the \psharp runtime.
In particular, the runtime is aware of nondeterminism due to interleaving of event handlers in different machines.
Each send operation to an ordinary (non-monitor) machine and each create operation of an ordinary (non-monitor) machine creates an
interleaving point where the runtime makes a scheduling decision.
The engine will repeatedly execute a program from start to completion, each time exploring a potentially different set of interleavings,
until it either reaches a bound (in number of iterations or time), or it hits a property violation.
The testing is fully automatic, has no false-positives (assuming an accurate environmental model),
and can reproduce found bugs by replaying buggy schedules.
After a bug is found, the engine generates a trace that represents the buggy schedule.
In contrast to typical logs generating during production, this log provides a global order of all communication events
and is easy to debug.

We have implemented two schedulers inside the \psharp systematic testing engine:
a \emph{random} scheduler that makes each nondeterministic choice randomly
and \emph{PCT} scheduler~\cite{burckhardt2010pct}.
It is straightforward to create a new scheduler by implementing the \texttt{ISchedulingStrategy} interface~\cite{desai2015systematic}
exposed by the \psharp libraries.
The interface exposes callbacks that are invoked by the \psharp runtime for taking decisions regarding which machine to schedule next,
and can be used for developing both generic and application-specific schedulers.

Normally, liveness checking requires the identification of an infinite fair execution that never satisfies the liveness property~\cite{schuppan2004efficient, musuvathi2008fair}. Prior work~\cite{schuppan2004efficient} has proposed that assuming a program with finite state space, a liveness property can be converted into a safety property. Other researchers proposed the use of heuristics and only exploring finite executions of an infinite state space system using random walks to identify if a liveness property is violated~\cite{killian2007life}.

\subsection{Handling intra-machine concurrency}
\label{sec:psharp:async}

Vanilla \psharp is able to capture and take control of the \emph{inter-machine concurrency} due to message passing, but is unable to systematically explore any interleavings due to \emph{intra-machine concurrency} (e.g. async/await or TPL). This is problematic as nowadays, with multicore machines being a commodity, programmers tend to write multithreaded code to exploit shared memory architectures and increase the performance of individual components of a distributed system.

As an example, the Live Azure Migration system uses the \texttt{async} and \texttt{await} \csharp 5.0 language primitives. Asynchronous code using async/await is more readable because it looks like traditional procedural code, but it is translated by the compiler to an event-driven state machine that is built on top of TPL to achieve performance. The key idea behind async/await is that a method declared as \texttt{async} can use internally the \texttt{await} keyword which allows the thread executing the method to wait on a TPL task, or any other \emph{awaitable} object, \emph{without} blocking. This is achieved as follows. When an \texttt{await} statement is executed, the code following the await is wrapped as a TPL task \emph{continuation} and the method returns to the caller. This continuation executes when the awaitable object has completed.

Developing a fully automatic and universal approach to handle intra-machine concurrency in .NET is very challenging, because there are many APIs that can be used for concurrency and synchronization (e.g. \texttt{System.Threading}, TPL, async/await, locks, semaphores) and each one has its own complexities. Although developers are willing to model the top-level message passing communication using \psharp, they are resistant in modeling the low-level threading and synchronization methods as this would be a very invasive procedure and such refactoring is unlikely to scale for legacy code.

To test our case studies, we decided to focus our efforts in handling async/await as providing a robust solution for a subset of the .NET threading APIs is more feasible than trying to handle arbitrary threading and synchronization. Our solution involves using a custom task scheduler whenever the bug-finding mode of the \psharp runtime is enabled, instead of the default TPL task scheduler. The \psharp task scheduler inherits from the \texttt{TaskScheduler} class, a low-level API that is responsible for enqueueing TPL tasks into threads.

Our approach works as follows. We start the task of the \emph{root} \psharp machine in our custom task scheduler. As long as any child tasks spawned by the root machine task do not explicitly start in another scheduler (including the default TPL scheduler), then they will be scheduled for execution in our custom task scheduler. Our custom scheduler intercepts the call to enqueue a task, creates a special machine called \texttt{TaskMachine} and \emph{wraps} the enqueued task inside this machine. The constructor of a \texttt{TaskMachine} takes as an argument a TPL task and stores it in an field. The \texttt{TaskMachine} has only a single state and when it is scheduled for execution by the \psharp systematic testing scheduler it will start executing the wrapped task and then immediately wait on its completion. This forces the lifetime of the task to become the lifetime of the machine and vice versa. Thus, when the \psharp systematic testing scheduler schedules the \texttt{TaskMachine}, it will also schedule the corresponding task. This means that when a \psharp program makes a call to an \texttt{async} method, then the task created in the backend will be automatically wrapped and scheduled.

For \texttt{await} statements, no special treatment is required because \texttt{await} statements are compiled into a continuation. The task associated with the continuation will also be wrapped and scheduled accordingly.

Regarding support for handling non-async/await concurrency primitives, we are currently investigate feasible approaches.
