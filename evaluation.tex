We report our experience of applying \psharp on the three case studies discussed in this paper. We aim to answer the following two questions:

\begin{enumerate}
\item How much human effort was spent in modeling the environment of a distributed system using \psharp?

\item How much computational time was spent in systematically testing a distributed system using \psharp?
\end{enumerate}

\subsection{Cost of environmental modeling}
\label{sec:eval:human_cost}

\newcommand{\colspacing}{\hspace{1.8em}}
\begin{table}[t]
\small
\centering
\setlength{\tabcolsep}{0.3em}
\begin{tabular}{l rrrrr rr}
\centering
\input{experiments/tables/statistics.tex}
\end{tabular}
\caption{Statistics from modeling the environment of the three Microsoft Azure-based systems under test.}
\label{tab:stats}
%\vspace{-3mm}
\end{table}

Environmental modeling is a core activity of using \psharp. It is required for \emph{closing the environment} of a system-under-test and making it amenable to systematic testing. Table~\ref{tab:stats} presents program statistics for our three case studies. We report: lines of code for the system-under-test (\#LoC); number of bugs found in the system (\#B); lines of \psharp code for the environmental model (\#LoC); number of machines (\#M); number of state transitions (\#ST); and number of action handlers (\#AH).

Modeling the environment of the Extent Manager in the Azure Storage vNext system required approximately 2 weeks of part-time developing. The \psharp model for testing this system is the smallest (in lines of code) from all three case studies. This was because the modeling effort was targeting the particular liveness bug that was haunting the developers of vNext. We are currently in the process of modeling other components of vNext, such as a ChainReplication and a Paxos system.

Modeling the Live Migration Table required \PDComment{waiting confirmation from
Matt}. The modeling effort was done in parallel with the development of the actual system. 
This is in contrast with the other two case studies discussed in this paper, where the modeling 
activity occurred independently and at a later stage of the development process.

Modeling Fabric required approximately 5 person months. Although this is a
significant amount of time, it is a one time effort (once per release). \PDComment{should say that 5 months is required for release 1.0, subsequent releases should be much faster} Our plan is to reuse the developed Fabric model 
for testing arbitrary user services built for the Azure Service Fabric system.

\subsection{Cost of systematic testing}
\label{sec:eval:machine_cost}

\setlength{\tabcolsep}{.72em}
\begin{table*}[t]
\small
\centering
\begin{tabular}{rl rrr rrr}
\centering
\input{experiments/tables/results.tex}
\end{tabular}
\caption{Results from running the \psharp random and PCT systematic testing schedulers for 100,000 iterations. We report: time in seconds to find a bug (Time to Bug); number of scheduling steps when a bug was found (\#SS); and if a bug was found with a particular scheduler (BF?).}
\label{tab:testing}
\end{table*}

Using \psharp we managed to uncover more than 10 serious bugs in our case studies. As discussed earlier in the paper, these bugs were hard to find with traditional testing techniques, but \psharp managed to uncover them and reproduce them in a small setting. According to the developers, the traces of \psharp were useful, as it allowed them to understand the source of the bug and fix it in a timely manner. After the developers fixed all the discovered bugs, we optionally reintroduced them one-by-one so that we can evaluate the effectiveness of different \psharp systematic testing strategies in finding these bugs.

Table~\ref{tab:testing} presents the results from running the \psharp systematic testing engine on each case study with a re-introduced bug using the random and PCT schedulers. We chose to use controlled random scheduling, because it has proven to be efficient for finding concurrency bugs~\cite{thomson2014sct, deligiannis2015psharp}. The CS column shows which case study corresponds to each bug: 1 is for the Azure Storage vNext; and 2 is for the Live Migration Table. \PDComment{update with 3 for Fabric}

We performed all experiments using the Windows PowerShell tool on a 2.50GHz Intel Core i5-4300U CPU with 8GB RAM running Windows 10 Pro 64-bit. We configured the engine to perform 100,000 iterations. The random seed for both schedulers was generated in each iteration using the \texttt{DateTime.Now.Millisecond} API which returns the current time in milliseconds. The PCT scheduler was further configured with a bug depth of 2 and a max number of scheduling steps of 500. All reported times are in seconds.

For the vNext case study, the random scheduler was able to reproduce the bug in less than 10 seconds. The reason that the number of scheduling steps to find the bug is much higher than the rest of the bugs in the table is that this bug is a liveness violation: as discussed in Section~\ref{sec:psharp:testing} we leave the program to run for a long time before checking if the liveness property holds. The PCT scheduler was unable to find the bug using the bug depth of 2, which suggests that the bug requires a larger depth bound to be found.

For the MigratingTable case study, the first 7 bugs in Table~\ref{tab:testing} were discovered using a \psharp test harness based on nondeterministically generated, but controlled by \psharp, input history. For each of these found bugs, we manually reviewed one of the bug traces to confirm if it reflected the expected bug. The remaining 4 bugs (denoted with $\diamond$) are known bugs that we were unable to find with the fully-randomized test harness in the 100,000 iterations. We believe this is due to unlucky random choices of inputs and schedules by the \psharp systematic testing engine. We wrote a custom \psharp test harness for each of these bugs, which allowed \psharp to quickly reproduce them. Note that using a custom test harness does not represent a testing method one could use to find unknown bugs in software. However, in this case the objective was to simply reproduce these known bugs.

The QueryStreamedBackUpNewStream bug in MigratingTable, that was found using \psharp, stands out because it reflects the type of oversight that tends to occur as designs evolve. We will not discuss the details of the bug due to space constraints, but \psharp managed to discover this bug in a matter of seconds. The MigratingTable developers spent about 10 minutes analyzing the trace to diagnose what was happening; granted, this was after days of experience analyzing traces. The developers had to extend the logging of \psharp with additional trace information to understand the bug. This is expected since \psharp only outputs trace information related to its communicating state machines. The trace information can be easily extended though; this was done in all our case studies.

%We started from the failure symptom: the virtual stream returned end-of-stream when according to the reference \texttt{SpecTable}, it should have returned an additional row with key 4.  We filtered the trace for actions by the same service machine and saw that $s_O$ was closed before the virtual stream had returned the row with key 4, but $s_N$ had already advanced past key 4 before the migrator inserted the row in the new table.  At first we found this phenomenon hard to believe, but soon we were convinced it reflected a gap in our design.

%This bug, which we named QueryStreamedBackUpNewStream, is in the implementation of a streaming read from the virtual table, which should return a stream of all rows in the table sorted by key.
%The essential implementation idea is to start streams $s_O$, $s_N$ from the old and new backend tables and merge the sorted streams by keeping track of the next row in each stream and returning the row with the lesser key.  In parallel, the migrator job is concurrently copying rows from the old table to the new table; we had satisfied ourselves that this concurrency would not cause any problems.  However, then we added support to the migrator job to delete the old table when it finishes copying, which triggers the virtual stream to close $s_O$.  Suppose the virtual stream is in a state in which the next row in $s_O$ has key $k_O$ and the next row in $s_N$ has key $k_N$, where $k_O < k_N$.  Further suppose that before the next read from the virtual stream, the migrator job copies a row with key $k$ ($k_O < k < k_N$) from the old table to the new table and then deletes the old table.  Since $s_O$ has not yet returned this row when it is closed and $s_N$ has already advanced to $k_N$, the row with key $k$ will be missed by the virtual stream.  A similar problem can occur if $s_N$ does not reflect rows inserted into the new table by the migrator job after $s_N$ is started, as allowed by the \texttt{IChainTable} specification.  Restarting $s_N$ when the old table is deleted fixes both variants of the bug.

% It might be nice to include excerpts of a trace like in migration-bug3-explanation.pptx.  Unfortunately, the trace in migration-bug3-explanation.pptx doesn't match my recollection of the original diagnosis, which I want to write about truthfully (the former looks like it involves a stale streaming read, while I'm fairly sure the latter involved only the $k_O < k < k_N$ case).  If it's important, I could try to get a new trace consistent with the original diagnosis. ~ Matt

%This bug took us only about 10 minutes to diagnose from the trace; granted, this is after we had days of experience analyzing MigratingTable traces and had added our own trace output to the test harness, since \psharp's built-in trace output is too low-level and does not include event payloads and other diagnostic data that is not passed between machines.

%We started from the failure symptom: the virtual stream returned end-of-stream when according to the reference \texttt{SpecTable}, it should have returned an additional row with key 4.  We filtered the trace for actions by the same service machine and saw that $s_O$ was closed before the virtual stream had returned the row with key 4, but $s_N$ had already advanced past key 4 before the migrator inserted the row in the new table.  At first we found this phenomenon hard to believe, but soon we were convinced it reflected a gap in our design.
