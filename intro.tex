Distributed systems are notoriously hard to design, implement and test~\cite{cavage2013there, laguna2015debugging, maddox2015test}. This is due to many well-known sources of \emph{nondeterminism}~\cite{chandra2007paxos}, such as race conditions in the asynchronous interaction between system components, the use of multithreaded code inside a component, unexpected node failures, unreliable communication channels and data losses, and interaction with (human) clients.
%
All these sources of nondeterminism translate into \emph{exponentially} many execution paths that a distributed system might potentially execute. A bug might hide deep inside one of these paths and only manifest under extremely rare corner cases~\cite{gray1986computers, musuvathi2008finding}.

Classic techniques that product groups employ to test, verify and validate their systems (such as code reviews, unit testing, stress testing and fault injection) are unable to capture and control all the aforementioned sources of nondeterminism, which causes the most tricky bugs being missed during testing and only getting exposed after a system has been put in production. Discovering and fixing bugs in production, though, is bad for business as it can cost a lot of money and many dissatisfied customers.

We interviewed engineers from the Microsoft Azure team regarding the top problems in distributed system development, and the unified response was that the most critical problem today is how to improve \emph{testing coverage} to find bugs \emph{before} a system goes in production. The need for better testing techniques is not specific to Microsoft; other companies, such as Amazon and Google, publicly acknowledge~\cite{newcombe2015aws} that testing methodologies have to improve to be able to reason about the correctness of increasingly more complex distributed systems.

Amazon recently published an article~\cite{newcombe2015aws} that describes their use of TLA+~\cite{lamport1994temporal} to detect distributed system bugs and prevent them from reaching production. TLA+ is a powerful specification language for verifying distributed protocols, but it is unable to verify the code that is actually being executed. The implied assumption is that a model of the system will be verified, and then the programmers are responsible to match what was verified with the source code of the real system. Although many design bugs can be caught with this approach, there is \emph{no guarantee} that the real distributed system will be free of bugs.

In this work, our goal is to \emph{test what is being executed}. We present a new methodology for testing legacy distributed systems and uncovering bugs before these systems are released in the wild. We achieve this using \psharp~\cite{deligiannis2015psharp}, an extension of the mainstream language \csharp that provides two key capabilities: (i) a flexible way of modeling the environment using simple language features; and (ii) a systematic concurrency testing framework that is able to capture and take control of all the nondeterminism in a real system (together with its modeled environment) and systematically explore execution paths to discover bugs.

We present three case studies of using \psharp to test production distributed systems for Windows Azure inside Microsoft: a distributed storage management system and a live migration protocol. Using \psharp, we managed to uncover a very subtle bug that was haunting developers for a long time as they did not have an effective way to reproduce the bug and nail down the culprit. \psharp uncovered this bug in a very small setting, which made it easy to examine traces, identify and eventually fix the problem.

To summarize, our contributions are as follows:

\begin{itemize}
\item We present a methodology that allows flexible modeling of the environment of a distributed system using simple language mechanisms.
\item Our infrastructure can test production code written in \csharp, which is a mainstream language.
\item We present three case studies of using \psharp to test production distributed systems, finding bugs that could not be found with traditional testing techniques.
\item ...
\end{itemize}
