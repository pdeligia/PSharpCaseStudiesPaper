Microsoft Azure Storage is a cloud storage system that provides customers the ability to store seemingly limitless amounts of data. It has grown from 10s of Petabytes (PB) in 2010 to Exabytes (EB) in 2015, with the total number of objects stored well-exceeding 60 trillion.

Azure Storage vNext is the next generation system, where the primary design target is to increase the scalability by 100x or more. Similar to the current system, vNext also employs containers, called {\em extents}, to store data. Extents are typically several Gigabytes each, consisting of many data blocks, and replicated over multiple {\em extent nodes}. Different from the current system, which employs a Paxos-based, centralized mapping between extents to ENs, vNext achieves its scalability target by employing a completely distributed mapping. In vNext, extents are divided into partitions, with each partition managed by a light-weight {\em Extent Manager}.

One of the many responsibilities of Extent Manager is to ensure that every extent maintains enough replicas in the system. For that, ExtMgr receives frequent periodic heartbeat messages from every EN. Failure of EN is detected by missing heartbeats. ExtMgr also receives less frequent, but still periodic {\em synchronization reports} from every EN. The sync reports list all the extents (and associated metadata) stored on the EN. Based on these two types of messages, ExtMgr identifies which ENs have failed and which extents are affected and missing replicas. ExtMgr, then, schedules tasks to repair the affected extents and distributes the tasks to ENs. ENs repair the extents from their existing replicas in the system and lazily update ExtMgr via future sync reports.

To ensure correctness, the developers of vNext have instrumented extensive, multiple levels of testing for Extent Manager.
$i)$ Unit testing sends emulated heartbeats and sync reports to ExtMgr and verifies the messages processed as expected.
$ii)$ Integration testing launches Extent Manager together with multiple ENs, injects EN failure and verifies that affected extents are eventually repaired.
$iii)$ Stress testing launches Extent Manager with many ENs and many extents. It keeps repeating the following process: injecting EN failure, launching new EN and verifying affected extents eventually repaired.

Despite of the extensive testing efforts, the vNext developers have been plagued by what appears to be an elusive bug in Extent Manager. All the unit test and integration test suites successfully pass every single time. However, the stress test suite could fail {\em from time to time} after very long executions, manifested as the replicas of some extents remain missing while never being repaired. The bug appears difficult to identify, reproduce and troubleshoot. First, it takes very long executions to trigger. Second, extent not being repaired is {\em not} a property that can be easily verified. In practice, the developers rely on very large time-out period to detect the bug. Finally, by the time that the bug is detected, very long execution traces have been collected, which makes manual inspection tedious and ineffective.

To uncover this bug and many other similar ones, the developers are in constant search of a generic and systematic approach for testing distributed storage systems.

%Since this is a rather typical dilemma in the development of distributed storage systems, a general and systematic approach hopefully would be very helpful to the developers and greatly increase their productivity.
