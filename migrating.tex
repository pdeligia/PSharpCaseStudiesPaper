% Remove the \emph on ``transparently'' and ``while'' again.  Pantazis, I'm
% imagining you were trying to emphasize what's interesting about the problem,
% but I think suggesting that this idea is new to the reader is insulting.
% ~ Matt 2015-12-31
Live Table Migration (MigratingTable) is a library designed to transparently migrate a data set between tables in the Azure storage service while an application is accessing this data set. This case study is particularly interesting because MigratingTable was \emph{co-developed} with its \psharp test harness. This co-development process resulted in the discovery of several tricky bugs before the system went into production (see \S\ref{sec:eval}). The MigratingTable testing effort differs from the vNext case study: the vNext developers focused on a single liveness property, while the MigratingTable test harness checks complete compliance with an interface (safety) specification.

MigratingTable provides a \emph{virtual table} that has an interface
similar to an ordinary Azure table. This interface is
named \texttt{IChainTable}. A virtual table is backed by a pair
of \emph{old} and \emph{new} \emph{backend} tables, both of which
implement \texttt{IChainTable}. A \emph{migrator} job is responsible
for moving all data from the old table to the new table in the
background. Meanwhile, each \emph{input} read and write operation
issued to the virtual table is implemented via a sequence
of reads and writes on the backend tables according to a protocol,
which intends to guarantee that when multiple applications issue input
operations to different MigratingTable instances with the same backend
tables, the output of these operations complies with the specification
of \texttt{IChainTable} for the combined \emph{input history} as if
all the operations were done on a single table. The goal of
using \psharp was to systematically test this property.

\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{img/modeled_migration}
\caption{The \psharp test harness of MigratingTable (each box with a dotted line represents one \psharp machine).}
\label{fig:mockedmigration}
\end{figure}

There are two main challenges behind testing MigratingTable: (i) the system is highly concurrent; and (ii) the input operations accept many parameters that affect the behavior in different ways. The developers could have chosen specific input histories to test, but they were not confident that they would cover the combinations of parameters that might trigger bugs. Instead, they used the \psharp API to sample from a distribution over input histories that they defined, which allowed all of the relevant parameters to vary within certain limits. They created a reference implementation of the \texttt{IChainTable} specification, called \texttt{SpecTable}, and compared the output of MigratingTable on the chosen input history to that of a \texttt{SpecTable} instance called the \emph{reference table}. The \texttt{SpecTable} implementation was reused for the backend tables of MigratingTable.
% I'm removing the claim that each bug is caught with positive probability per
% run because it's too awkward to explain here and it's nothing specific to
% MigratingTable.  Also, we can't quite appeal to the small scope hypothesis in
% its original form because I hand-picked which parameters to vary and what
% limits to use.  The value of the input generator should be clear enough from
% the above. ~ Matt 2015-12-31

Figure~\ref{fig:mockedmigration} illustrates the \psharp test harness of MigratingTable. The harness consists of a \texttt{Tables} machine that contains the backend tables and the reference table and serializes all operations on these tables; a set of \texttt{Service} machines that contain identically configured instances of MigratingTable; and a \texttt{Migrator} machine that performs the background migration. Each \texttt{Service} machine issues a random sequence of input operations to its MigratingTable, which sends the necessary operations to the backend tables via \psharp events. The developers instrumented MigratingTable to report the \emph{linearization point} of each input operation, i.e., the time at which it takes effect on the single virtual table, so the test harness could perform the operation on the reference table at the same time. (More precisely, after processing each backend operation, the \texttt{Tables} machine enters a \psharp state that blocks all further work until MigratingTable reports whether the backend operation was the linearization point and, if so, the input operation has been completed on the reference table. This way, the rest of the system never observes the reference table to be out of sync with the virtual table.)
% Note: If the tables were observed to be out of sync, it could cause both false
% positives and false negatives. ~ Matt 2015-12-31

For further information about MigratingTable and its \psharp test harness, we refer the reader to the source repository~\cite{migratingtable-src}.

%\begin{figure}[t]
%\centering
%\includegraphics[width=\linewidth]{img/livemigration}
%\caption{Resharding a data set when a third Azure storage account is added. Two key ranges are each migrated to the new account using a MigratingTable instance (abbreviated MTable).}
%\label{fig:livemigration}
%\end{figure}

% N.B. Artifact Services is mentioned at http://research.microsoft.com/en-us/people/schulte/.  Hopefully it's OK to reveal that it was the system in this case study. ~ Matt 2015-08-17
%The initial motivation for MigratingTable was to solve a scaling problem for Artifact Services, an internal Microsoft system with a data set that is sharded across tables in different Azure storage accounts because it exceeds the limit on traffic supported by a single Azure storage account.  As the traffic continues to grow over time, the system needs to reshard the data set across a greater number of Azure storage accounts without interrupting service.  During such a resharding, our sharding manager will identify each key range that should migrate to a different table, and we will use a separate MigratingTable instance for each such key range to actually perform the migration (Figure~\ref{fig:livemigration}).  MigratingTable may also be useful to migrate data to a table with different values of configuration parameters that Azure does not support changing on an existing table, such as geographic location.

%Since we were designing a new concurrent protocol that we expected to become increasingly complex over time as we add optimizations, we planned from the beginning to maintain a \psharp test harness along with the protocol to maintain confidence in its correctness.

%MigratingTable implements an interface called \texttt{IChainTable}, which provides the core read and write functionality of the original Azure table API with one exception: it provides \emph{streaming reads} with a weaker consistency property than multi-page reads in the original API, since the original property would have been difficult to achieve for no benefit to applications we could foresee.  MigratingTable requires that its backend tables also implement \texttt{IChainTable}, and we wrote a simple adapter to expose physical Azure tables as \texttt{IChainTable}.

% N.B. \texttt{SpecTable} = InMemoryTableWithHistory in the current codebase. ~ Matt 2015-08-17

%\psharp takes control of the choice of input history, as well as the schedule, so both can be reproduced using a single random seed. Then, under the \emph{small scope hypothesis} that any bug in MigratingTable leads to incorrect output for at least one input history in our distribution, we have a positive probability of detecting this incorrect output on each \PTComment{execution [iteration]} of the \psharp test.

%If we had no formalization of the specification and had to rely on expected outputs worked out by hand, this might be the best we could do.  However, since the \texttt{IChainTable} specification is relatively simple and is almost deterministic under sequential calls, it was straightforward to write an in-memory reference implementation called \texttt{SpecTable} to which we can compare the output of MigratingTable on an arbitrary input history.  This gave us the attractive option to sample from a distribution we defined over all possible input histories within certain bounds.

%It was convenient to let \psharp control the choice of input history as well as the schedule so we could reproduce both using a single random seed.  Then, under the \emph{small scope hypothesis} that any bug in MigratingTable leads to incorrect output for at least one input history in our distribution, we have a positive probability of detecting this incorrect output on each \PTComment{execution [iteration]} of the \psharp test.

%All of our input histories include two application processes.  Each process performs either a single streaming read or a sequence of two atomic calls, each a read or a batch write.  Each batch write call includes one or two operations, where the operation type is chosen from the set supported by \texttt{IChainTable} (Insert, Replace, Merge, Delete, InsertOrReplace, InsertOrMerge, DeleteIfExists) and the row key is chosen from $\{0, \ldots, 5\}$.  If the operation requires an If-Match value, it is equally likely to be \texttt{*}, the current ETag of the row (if it exists), or some non-matching value.  Finally, the new entity includes a user-defined property \texttt{isHappy} whose value is equally likely to be true or false.  For both atomic and streaming reads, the filter expression is equally likely to be empty (i.e., match everything), \texttt{isHappy eq true}, or \texttt{isHappy eq false}.

%As mentioned above, the \texttt{IChainTable} specification is almost deterministic under sequential calls; the only nondeterminism is in the results of streaming reads.  Given a streaming read, \texttt{SpecTable} can compute the set of all results that are compliant with the specification, so we can simply check if the result of MigratingTable is in this set.

%To test MigratingTable, we must supply it with backing tables.  We use \texttt{SpecTable} for this purpose as well, with \psharp choosing the actual result of each streaming read from the valid set.  Our correctness property is then:
% Convert to some theorem-like environment? ~ Matt
%\begin{quote}
%For every execution trace of a collection of MigratingTables backed by the same pair of \emph{old} and \emph{new} \texttt{SpecTable}s in parallel with the migrator job, there exists a linearization of the combined input history such that the output in the original trace matches the output of a ``reference'' \texttt{SpecTable} on the linearized input.
%\end{quote}
%

%The MigratingTable was instrumented to report the intended \emph{linearization point} of each input call, which in our setting is always one of the corresponding \emph{backend calls} to the backend tables (often the last).  Specifically, after each backend call completes, MigratingTable reports whether that call was the linearization point, which may depend on the result of the call.  This makes it possible to check the correctness property as the model executes.

%We use the \psharp random scheduling strategy; we were afraid that an exhaustive strategy would only be feasible within bounds so low that we would miss some bugs.

%We wanted to implement the core MigratingTable algorithms in \csharp ``async/await'' code, like most of Artifact Services, to achieve both good readability and good performance.  We used a method similar to that described in \S\ref{sec:psharp:async} to bring the generated TPL tasks under the control of the \psharp scheduler.  Then we implemented an ``async'' RPC mechanism based on the .NET RealProxy class that automates the generation of proxies for objects hosted by other \psharp machines (in our setting, the service machines use proxies for the \texttt{SpecTable}s and various auxiliary objects hosted by the tables machine).  When a machine calls a method on a proxy, the proxy sends a \psharp message to the host machine, causing it to execute the method call on the original object and send back the result, which the proxy then returns.  Thus, the use of these proxies as \texttt{IChainTable} backends is transparent to the MigratingTable library, thanks to dynamic dispatch.
